---
title: "MovieLens HarvardX Capstone"
author: "Ana Hristova"
date: "05/06/2020"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1. Introduction

Recommendation systems use ratings given by users for specific products/ services to make recomendations based on predictions. Ratings given by a user or users exhibiting similar characteristics are used to predict a rating for an item, which, if high, is used to recommend the item to the user. Ratings typically range from 1 to 5, where 1 means the item is not desirable and 5 indicates the customer would love it.

Online retail companies as well as video/ music streaming services amongst others use such systems to tailor their content to each user.

This project uses the MovieLens 10M dataset generated by GroupLens reasearch lab and released in January 2009 to predict movie ratings.

## 2. Data

The MovieLens dataset contains 10M observations of six variables and for the purpose of creating a predictive model and validating its predidictions, it is split into two sets - edx, containing 90% of the observations and validation, containing the remaining 10% and only used to calculate the RMSE of the output of the model vs the actual ratings.

The dataset is provided clean, with no missing values.

## 3. Methodology

As the aim of this project is to create a predictive model that predicts ratings for a set of movies and users, simulating a real modelling environment, only the edx data set was used for the exploratory analysis of the data.

The exploratory analysis of the data includes deep dive into each variable, to understand any dependancies and data types included.

Following the exploratory analysis, the edx dataset was split into train and test set to allow for examining different models and variables and to arrive to a model that would deliver the desired RMSE of below 0.8649.

The predictive models explored are:
* Basic model using only the average rating
* Model using just the movie effect
* Model using a combination of movie and user effect
* Model using a combination of movie, user and genre effect
* Regularized model using a combination of movie, user and genre effect
* Regularized model using a combination of movie, user, genre and time of rating effect

## 4. Exploratory data analysis

### 4.1. Exploring the data set

```{r, echo = FALSE, include = FALSE}
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")
if(!require(ggrepel)) install.packages("ggrepel", repos = "http://cran.us.r-project.org")
if(!require(scales)) install.packages("scales", repos = "http://cran.us.r-project.org")
if(!require(lubridate)) install.packages("lubridate", repos = "http://cran.us.r-project.org")
if(!require(knitr)) install.packages("knitr", repos = "http://cran.us.r-project.org")

# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings <- fread(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                 col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
colnames(movies) <- c("movieId", "title", "genres")
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(levels(movieId))[movieId],
                                           title = as.character(title),
                                           genres = as.character(genres))

movielens <- left_join(ratings, movies, by = "movieId")

# Validation set will be 10% of MovieLens data
set.seed(1, sample.kind="Rounding")
# if using R 3.5 or earlier, use `set.seed(1)` instead
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set
validation <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set
removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

################################
# Exploratory data analysis
################################
# Dimensions of the dataset ----
dim_dat<- dim(edx)
n_var<- dim_dat[2] #number of variables
n_obs<- dim_dat[1] #number of observations

#Exploring the variables ----
vars<-names(edx) #variable names
n_users<- n_distinct(edx$userId) #number of users included in the dataset
n_movies<- n_distinct(edx$movieId) #number of movies included in the dataset
n_ratings<- n_distinct(edx$rating) #number of possible ratings
n_genres<- edx %>%  # number of genres
  group_by(genres)%>% 
  distinct(genres) %>%
  separate_rows(genres, sep = "\\|") %>% #some movies have multiple genres listed
  summarise(n_distinct(genres))
class(edx$timestamp) <- c('POSIXt','POSIXct') # turning the timestmap in a user friendly format (aka date)
first_rating<- min(edx$timestamp) # when did the first rating in the data set occur
last_rating<- max(edx$timestamp) # # when did the last rating in the data set occur


```

The edx dataset contains `r n_var` variables and `r n_obs` observations. The variables included are:
`r vars`

The set includes data for `r n_users` users who have rated `r n_movies` movies that belong to different combinations of `r n_genres` possible genres. The first rating included in the dataset is from `r first_rating` and the last is from `r last_rating`.

### 4.2. Exploring the users included in the dataset

There are `r n_users` users included in the edx dataset.

**User Ratings**
``` {r, echo = FALSE}
## Exploring the users ----
users<- edx %>%
  group_by(userId) %>%
  summarise(n_ratings = n()) %>%
  arrange(desc(n_ratings))

summary(users$n_ratings) # finding min, max, avg and median ratings per user
```

The average number of ratings provided by the users is `r round(mean(users$n_ratings))`. One user has been particularly active, providing `r max(users$n_ratings)` ratings in total, while the minimum number of ratings submitted by a user is `r min(n_ratings)`, with median number of ratings `r median(users$n_ratings)`, suggesting that user ratings are heavily influenced by a small number of users who have provided exceptionally high number of ratings.

This is visualised in the below plot showing user activity.

``` {r, echo = FALSE, fig.pos = 'h'}
# visualising user activity
users %>%
  ggplot(aes(x=userId,y=n_ratings, colour = n_ratings))+
  geom_point()+
  scale_colour_gradientn(colours = rainbow(7), name = "Number of Ratings")+
  scale_y_log10()+  #using log10 scale to normalise for outliers (users with exceptionally high number of ratings)
  labs(title = "Ratings per User", x = "UserId", y = "Number of Ratings (log10 scale)")+
  theme_classic()+
  theme(legend.position = "bottom",
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank())
```








 
Next, we will look at the user activity for each year included in the data (1995 - 2009).

``` {r, echo = FALSE, fig.pos = 'h', fig.height = 3.5}
#active users by year
users_by_year<- edx %>%
  mutate(year = year(timestamp)) %>%
  group_by(year) %>%
  summarise(users = n_distinct(userId)) %>%
  arrange(desc(users))

summary(users_by_year$users)

#plot users by year
users_by_year %>% 
  arrange(year) %>%
  ggplot(aes(x=year, y=users))+
  geom_bar(stat="identity")+
  theme_classic()+
  labs(title = "Users by Year", x = "Year", y="Number of users")

```

From the Users by Year plot above we see that 1995 and 2009 are the years with the lowest number of active users. This is due to the fact that the data for these years is only partial. The year with the highest number of active users is `r users_by_year$year[1]` where there were `r users_by_year$users[1]` active users. In the following section we will examine how that affects the ratings provided.

### 4.3. Exploring the ratings

``` {r, echo = FALSE, fig.pos = 'h', fig.height = 3.5}
edx %>%
  ggplot(aes(y=rating))+
  geom_boxplot()+
  theme_classic()+
  labs(title = "Distribution of Ratings", y="Rating")+
  theme(axis.title.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.text.x = element_blank())

```

The Distribution of Ratings boxplot shows that generally people like the movies they have rated, with average rating of nearly 4. Most ratings provided are above 3 stars with only a handful of ratings being below or equal to 1 star.

Looking at how the distribution of ratings varies per year, the .5 ratings appear to be introduced in 2003. Further investigation confirms they were introduced on 18 Feb 2003, and before that only whole star ratings were permitted.

``` {r, echo = FALSE, fig.pos = 'h', fig.height = 3.5}
#plot distribution of ratings by year
edx %>%
  mutate(year = year(timestamp)) %>%
  ggplot(aes(group=year,x=year,y=rating))+
  geom_boxplot()+
  theme_classic()+
  labs(title = "Distribution of Ratings by Year", x = "Year", y="Rating")
```

The number of ratings per year appears to vary significantly. 1995 and 2009 are the years with the fewest ratings provided, which is explained by the fact that we only have partial records for this years and in line with the lower number of actve users, also due to the same reason.

``` {r, echo = FALSE, fig.pos = 'h', fig.height = 3.5}
# ratings over time
year_ratings<- edx%>%
  mutate(year = year(timestamp)) %>%
  group_by(year) %>%
  summarise(n_ratings = n(), avg = mean(rating), med=median(rating), sd=sd(rating))

#plot ratings by year
year_ratings %>% 
  arrange(year) %>%
  ggplot(aes(x=year, y=n_ratings))+
  geom_bar(stat="identity")+
  theme_classic()+
  labs(title = "Ratings per Year", x = "Year", y="Number of ratings")

```

Lets explore the relationship between the number of ratings per year and the number of active users per year.

``` {r, echo = FALSE, fig.pos = 'h', fig.height = 3.5}
# plot user - number of ratings per year relationship
edx%>%
  mutate(year = year(timestamp)) %>%
  group_by(year) %>%
  summarise(n_ratings = n(), n_users = n_distinct(userId)) %>%
  ggplot(aes(x=n_ratings, y=n_users))+
  geom_line()+
  theme_classic()+
  labs(title = "Active Users vs Number of Ratings", x = "Number of Ratings", y="Number of Users")

cor<-edx%>%
  mutate(year = year(timestamp)) %>%
  group_by(year) %>%
  summarise(n_ratings = n(), n_users = n_distinct(userId)) %>%
  summarise(cor(n_users, n_ratings))
```

Unsurprisingly, we notice that the more active users there are, the more ratings are provided, with a strong positive correlation of `r round(cor,2)`.


Exploring the ratings by user, we notice that the average rating is 3 to 4 stars, with a small number of users that loved every movie they saw and even fewer who hated every movie they saw. The standard deviation of ratings by user plot shows that the majority of users are consistent with theyr ratings with about 1 star standard deviation, with only a few people who gave a wide range of ratings.

``` {r, echo=FALSE, fig.pos = 'h', fig.show='hold', out.width = '50%'}

# user ratings
user_ratings<- edx %>%
  group_by(userId)%>%
  summarise(n_ratings = n(), avg = mean(rating), med = median(rating), sd = sd(rating)) %>%
  arrange(desc(n_ratings))


#plot avg rating per user
user_ratings %>%
  ggplot(aes(x=userId, y=avg, colour = avg))+
  geom_point(alpha=0.1)+
  scale_colour_gradientn(colours = rainbow(5), name = "Average Ratings")+
  theme_classic()+
  labs(title = "Average Rating by User", x = "UserId", y="Average Rating")

#plot sd of rating per user
user_ratings %>%
  ggplot(aes(x=userId, y=sd, colour = sd))+
  geom_point(alpha=0.1)+
  scale_colour_gradientn(colours = rainbow(5), name = "Standard Deviation of Ratings")+
  theme_classic()+
  labs(title = "Standard Deviation of Rating by User", x = "UserId", y="Standard Deviation of Rating")
```

### 4.4.Exploring the movies

There are `r n_movies` movies included in the edx dataset.
 
**The 5 most rated movies are**:

```{r, echo=FALSE}
movies<- edx %>%
  group_by(title) %>%
  summarise(n_ratings = n(), avg = mean(rating), sd = sd(rating)) %>%
  arrange(desc(n_ratings))

head(movies) %>% kable
```

In the below chart, we see that the number of movies rated by year follows the same pattern as the number of ratings per year. 1995 and 2009 have the lowest numbe of movies rated due to them being only partially inclueded in the dataset. 2000, 2005 and 1996 are the years with most movies rated.

```{r, echo=FALSE, fig.pos = 'h', fig.height = 3.5}
# movies rated per year
movies_by_year<- edx %>%
  mutate(year = year(timestamp)) %>%
  group_by(title, year) %>%
  summarise(n_ratings = n(), avg = mean(rating), sd = sd(rating))%>%
  arrange(year)

# plot movies rated by year 
movies_by_year %>%
  ggplot(aes(x = year, y = n_ratings))+
  geom_bar(stat = "identity")+
  theme_classic()+
  labs(title = "Movies rated by Year", x = "Year", y="Number of movies")

```

The year in which a movie is produced is included in the movie title column after the movie title, which permits us to explore how many movies are produced by year of production in the graph below. There is an exponential growth in movies produced from 1910 until 2000 which then drops in the following years.


```{r, echo=FALSE, fig.pos = 'h', fig.height = 3.5}
# movies by release year (release year contained in movie title)
movie_year<- edx %>%
  mutate(title = str_trim(title)) %>% #removing blank spaces
  extract(title, c("title", "release_year"), regex = "^(.*) \\(([0-9 \\-]*)\\)$",remove = TRUE, convert = TRUE) #splitting the title into title and release year columns

# plot movies produced by year
movie_year %>%
  group_by(release_year, title) %>%
  summarise(n_movies = n_distinct(movieId)) %>%
  ggplot(aes(x=release_year, y=n_movies))+
  geom_bar(stat = "identity")+
  labs(title = "Movies Produced by Year", x = "Year", y="Number of Movies")+
  theme_classic()+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

The number of ratings by movie release year follows a similar pattern with the exponential growth peaking  for movies released in the 90's. Tis is likely due to the fact that the ratings included in the data set begin in the 90's and movies which were then new and popular have had the longest time to receive ratings.

```{r, echo=FALSE, fig.pos = 'h', fig.height = 3.5}
#plot number of ratings by production year
movie_year %>%
  group_by(release_year, title) %>%
  summarise(n_ratings = n()) %>%
  ggplot(aes(x=release_year, y=n_ratings))+
  geom_bar(stat = "identity")+
  labs(title = "Number of ratings by Movie Release Year", x = "Year", y="Number of Ratings")+
  theme_classic()+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

The top 10 movies **by number of ratings received** are:

```{r, echo=FALSE}

# 10 most reviewed movies
movies %>% slice(1:10) %>% kable
```

The average ratings for these movies vary from 3.66 to 4.46 which is a large variance for this dataset. Let's look at the top 10 movies **by rating**:

```{r, echo=FALSE}
#Top 10 movies by rating
movies %>% 
  arrange(desc(avg)) %>%
  slice(1:10) %>% kable
```

Those movies have a very small number of ratings (between 1 and 4), so to gain an understanding of the most popular movies (those with a large number of ratings and a high average rating), let's review the top 10 movies **by rating with 1k or more ratings**:

```{r, echo=FALSE}
#Top 10 movies by rating with over 1k ratings
movies %>%
  filter(n_ratings >=1000) %>%
  arrange(desc(avg)) %>%
  slice(1:10) %>% kable
```

Now this is a list of well known classics which are always listed in "must watch" movie lists!

### 4.5. Exploring the genres

The last variable to explore are the movie genres.

``` {r, echo = FALSE, results='hide'}
genres<- edx %>%
  group_by(genres) %>%
  summarise(sum_ratings = sum(rating), n_ratings = n())# we can see that movies ofte have more than one genre

g_dim<- dim(genres)

```

The movies included in the edx dataset belong to combinations of 19 genres with 1 movie having no genre listed. There are `r g_dim[1]` combinations of genres included.

Lets look at a breakdown of the genres.

``` {r, echo = FALSE, fig.pos = 'h', fig.height = 3.5}
#breaking the genres down
genres <- genres %>%
  separate_rows(genres, sep = "\\|")

genres_ratings <- genres %>%
  group_by(genres) %>%
  summarise(n_ratings = sum(n_ratings), avg = sum(sum_ratings)/sum(n_ratings) ) %>%
  arrange(desc(n_ratings))

# plot genres by number of ratings
genres_ratings %>%
  ggplot(aes(x = reorder(genres, -n_ratings), y=n_ratings))+
  geom_bar(stat = "identity")+
  theme_classic()+
  labs(title = "Number of Ratings by Genre", x = "Genres", y="Number of Ratings")+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

The genres that have received the highest number of ratings are Drama, Comedy and Action, which aligns with the genres of most blockbuster movies which are likely to be viewed by many people and receive many ratings. 

``` {r, echo = FALSE, fig.pos = 'h', fig.height = 3.5}
#plot genres by avg rating
genres_ratings %>%
  ggplot(aes(x = reorder(genres, -avg), y=avg))+
  geom_point()+
  theme_classic()+
  labs(title = "Average Rating by Genre", x = "Genres", y="Average Rating")+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  ylim(3,5) #as avg ratings don't vary much
```

When we look at the average rating for each genre, we notice that the highest rated genres Film-Noir, Documentary and War were on the tail of the graph that showed the genres by number of ratings. We can assume these genres are watched and reviewed mostly by connoiseurs who generally enjoy these particular genres.

To get an understanding of the most popular genres - those with high avereage rating and large volume of reviews, the below graph shows genres with over 1M ratings ranked by average rating. Drama appears on first position again, which is also aligned with the most popular movies seen above.

``` {r, echo = FALSE, fig.pos = 'h', fig.height = 3.5}
#plot the most popular genres by avg rating (popular = more than 1M ratings)
#required packages: ggrepl + scales
genres_ratings %>%
  filter(n_ratings >= 1000000) %>%
  mutate(n_r = paste(round(n_ratings/1e6,1),"M")) %>%
  ggplot(aes(x = reorder(genres, -avg), y=avg, label = n_r))+
  geom_bar(stat = "identity")+
  geom_text(aes(label = n_r), vjust = -1)+
  theme_classic()+
  labs(title = "Average Rating by Genre with more than 1M ratings", x = "Genres", y="Average Rating")+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  scale_y_continuous(limits = c(3,5), oob=rescale_none) #as avg ratings don't vary much
```

## 5. Creating predictive model

In this section we will take a look at 6 predictive models to choose the best one amongst them, which will yield a RMSE of below 0.86490.

For this purpose, the edx dataset explored above is split into a train and test set, which will allow for the model to be tested and fitted before applying the best one to the validation set.

``` {r, echo = FALSE, include = FALSE}
## Creating train and test sets----
set.seed(1, sample.kind = "Rounding")
test_index<- createDataPartition(y=edx$rating, times = 1, p=0.2, list = FALSE)
train_set<- edx[-test_index,]
temp<- edx[test_index,]

# Make sure userId and movieId in test set are also in train set
test_set <- temp %>% 
  semi_join(train_set, by = "movieId") %>%
  semi_join(train_set, by = "userId")

# Add rows removed from test set back into train set
removed <- anti_join(temp, test_set)
train_set <- rbind(train_set, removed)

#remove objects that we won't need anymore
rm(temp, removed, test_index)

# Write RMSE function ----
RMSE <- function(true_ratings, predicted_ratings){
  sqrt(mean((true_ratings - predicted_ratings)^2))
}
options(digits = 7)

```

### 5.1. Basic model with just the average

For this model, we use the avergae of the ratings in the train set as our predicted value for the ratings in the test set.The RMSE of this method is over 1, which is much larger than the one we are trying to achieve. 

``` {r, echo = TRUE}
mu_hat<- mean(train_set$rating)
naive_rmse<- RMSE(test_set$rating, mu_hat)


#creating a tibble for storing RMSE results
rmse_results <- tibble(method = "Just the average", RMSE = naive_rmse)

knitr::kable(rmse_results)

```

Let's start using the variables to try and get better predictions.

### 5.2. Model using just the movie effect

In this model we will explore what effect do the movies have in estimating the rating by calculating movie bias. From the table we can see that the RMSE has indeed improved slightly but is far from the desired value.

``` {r, echo = TRUE, warning = FALSE}
mu <- mean(train_set$rating) 
movie_avgs <- train_set %>% 
  group_by(movieId) %>% 
  summarize(b_i = mean(rating - mu))

predicted_ratings <- mu + test_set %>% 
  left_join(movie_avgs, by='movieId') %>%
  pull(b_i)
movie_rmse<-RMSE(predicted_ratings, test_set$rating)

rmse_results<- bind_rows(rmse_results, data_frame(method = "Movie effect model",
                                                  RMSE = movie_rmse))
knitr::kable(rmse_results)


```

### 5.3. Model using a combination of movie and user effect

Building on the previous model, we will now include both movie and user bias as ratings differ by movie but also two different users can give the same movie a different rating due to their own preferences. This imporoved further our model.

``` {r, echo = TRUE}
user_avgs <- train_set %>% 
  left_join(movie_avgs, by='movieId') %>%
  group_by(userId) %>%
  summarize(b_u = mean(rating - mu - b_i))

predicted_ratings <- test_set %>% 
  left_join(movie_avgs, by='movieId') %>%
  left_join(user_avgs, by='userId') %>%
  mutate(pred = mu + b_i + b_u) %>%
  pull(pred)

movie_user_rmse<-RMSE(predicted_ratings, test_set$rating)
rmse_results<- bind_rows(rmse_results, data_frame(method = "Movie + user effect model",
                                                  RMSE = movie_user_rmse))
knitr::kable(rmse_results)


```

### 5.4. Model using a combination of movie, user and genre effect

As we are still away from achieveing the desired RMSE in our train and test sets, lets look into including the bias genre introduces into the ratings, as different users enjoy different genres.

``` {r, echo = TRUE}
genre_avgs <- train_set %>% 
  left_join(movie_avgs, by='movieId') %>%
  left_join(user_avgs, by = 'userId') %>%
  group_by(genres) %>%
  summarize(b_g = mean(rating - mu - b_i - b_u))

predicted_ratings <- test_set %>% 
  left_join(movie_avgs, by='movieId') %>%
  left_join(user_avgs, by='userId') %>%
  left_join(genre_avgs, by = 'genres') %>%
  mutate(pred = mu + b_i + b_u +b_g) %>%
  pull(pred)

movie_user_genre_rmse<-RMSE(predicted_ratings, test_set$rating)
rmse_results<- bind_rows(rmse_results, data_frame(method = "Movie + user + genre effect model",
                                                  RMSE = movie_user_genre_rmse))
knitr::kable(rmse_results)

```

### 5.5. Regularized model using a combination of movie, user and genre effect

The RMSE is getting closer to the desired value but there is still some space for tunning the model. During the exploratory data analysis we noticed that some movies have thousands or ratings while others only a handful, some users gave many ratings, some gave few and some genres were much more popular than others. In order to fit our model better we need to include a penalty term that will help even the playing field. First we have to find out what that penalty term should be by running the model with several different terms.

``` {r, echo = TRUE}
lambdas <- seq(0, 10, 0.25) #looking for the best lambda (penalty trem)

rmses <- sapply(lambdas, function(l){
  
  mu <- mean(train_set$rating)
  
  b_i <- train_set %>% 
    group_by(movieId) %>%
    summarize(b_i = sum(rating - mu)/(n()+l))
  
  b_u <- train_set %>% 
    left_join(b_i, by="movieId") %>%
    group_by(userId) %>%
    summarize(b_u = sum(rating - b_i - mu)/(n()+l))
  
  b_g <- train_set %>% 
    left_join(b_i, by="movieId") %>%
    left_join(b_u, by = "userId") %>%
    group_by(genres) %>%
    summarize(b_g = sum(rating - b_i - b_u - mu)/(n()+l))
  
  predicted_ratings <- 
    test_set %>% 
    left_join(b_i, by = "movieId") %>%
    left_join(b_u, by = "userId") %>%
    left_join(b_g, by = "genres") %>%
    mutate(pred = mu + b_i + b_u + b_g) %>%
    pull(pred)
  
  return(RMSE(predicted_ratings, test_set$rating))
})

lambda <- lambdas[which.min(rmses)]
lambda

```

The best penalty term in this model which accounts for user, movie and genre effect is `r lambda`. Knowing that, we can now run the model and see that RMSE has indeed improved.

``` {r, echo = TRUE}
mu <- mean(train_set$rating)

b_i <- train_set %>% 
  group_by(movieId) %>%
  summarize(b_i = sum(rating - mu)/(n()+lambda))

b_u <- train_set %>% 
  left_join(b_i, by="movieId") %>%
  group_by(userId) %>%
  summarize(b_u = sum(rating - b_i - mu)/(n()+lambda))

b_g <- train_set %>% 
  left_join(b_i, by="movieId") %>%
  left_join(b_u, by = "userId") %>%
  group_by(genres) %>%
  summarize(b_g = sum(rating - b_i - b_u - mu)/(n()+lambda))

predicted_ratings <- 
  test_set %>% 
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = "userId") %>%
  left_join(b_g, by = "genres") %>%
  mutate(pred = mu + b_i + b_u + b_g) %>%
  pull(pred)

regularised_m_u_g_rmse<-RMSE(predicted_ratings, test_set$rating)

rmse_results<- bind_rows(rmse_results, data_frame(method = "Regularised movie + user + genre effect model",
                                                  RMSE = regularised_m_u_g_rmse))
knitr::kable(rmse_results)

```

### 5.6. Regularized model using a combination of movie, user, genre and time of rating effect

Lastly, we also noticed that the number of ratings and their average also vary by year, so we will add one more bias term - the timestamp. Agan due to the variability accross users, movies, genres and time of rating, we first calculate penalty term.

``` {r, echo = TRUE}
# regularising the estimates to account for variability in the number of observations

# transforming the timestamp into date format
class(train_set$timestamp)<- c('POSIXt','POSIXct')
class(test_set$timestamp)<- c('POSIXt','POSIXct')

train_set$timestamp<- format(as.Date(train_set$timestamp), "%Y-%m")
test_set$timestamp<- format(as.Date(test_set$timestamp), "%Y-%m")

lambdas <- seq(0, 10, 0.25) #looking for the best lambda (penalty trem)

rmses <- sapply(lambdas, function(l){
  
  mu <- mean(train_set$rating)
  
  b_i <- train_set %>% 
    group_by(movieId) %>%
    summarize(b_i = sum(rating - mu)/(n()+l))
  
  b_u <- train_set %>% 
    left_join(b_i, by="movieId") %>%
    group_by(userId) %>%
    summarize(b_u = sum(rating - b_i - mu)/(n()+l))
  
  b_g <- train_set %>% 
    left_join(b_i, by="movieId") %>%
    left_join(b_u, by = "userId") %>%
    group_by(genres) %>%
    summarize(b_g = sum(rating - b_i - b_u - mu)/(n()+l))

  b_t <- train_set %>% 
    left_join(b_i, by="movieId") %>%
    left_join(b_u, by = "userId") %>%
    left_join(b_g, by="genres") %>%
    group_by(timestamp) %>%
    summarize(b_t = sum(rating - b_i - b_u-b_g - mu)/(n()+l))
  
  predicted_ratings <- 
    test_set %>% 
    left_join(b_i, by = "movieId") %>%
    left_join(b_u, by = "userId") %>%
    left_join(b_g, by = "genres") %>%
    left_join(b_t, by="timestamp") %>%
    mutate(pred = mu + b_i + b_u + b_g + b_t) %>%
    pull(pred)
  
  return(RMSE(predicted_ratings, test_set$rating))
})

lambda <- lambdas[which.min(rmses)]

```

The best penalty term that minimises RMSE is now `r lambda`.

Running this more finely tuned model finally delivers RMSE in the desirable range.

``` {r, echo = FALSE}
# running the model with lambda = 5
mu <- mean(train_set$rating)

b_i <- train_set %>% 
  group_by(movieId) %>%
  summarize(b_i = sum(rating - mu)/(n()+lambda))

b_u <- train_set %>% 
  left_join(b_i, by="movieId") %>%
  group_by(userId) %>%
  summarize(b_u = sum(rating - b_i - mu)/(n()+lambda))

b_g <- train_set %>% 
  left_join(b_i, by="movieId") %>%
  left_join(b_u, by = "userId") %>%
  group_by(genres) %>%
  summarize(b_g = sum(rating - b_i - b_u - mu)/(n()+lambda))

b_t <- train_set %>% 
  left_join(b_i, by="movieId") %>%
  left_join(b_u, by = "userId") %>%
  left_join(b_g, by="genres") %>%
  group_by(timestamp) %>%
  summarize(b_t = sum(rating - b_i - b_u-b_g - mu)/(n()+lambda))

predicted_ratings <- 
  test_set %>% 
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = "userId") %>%
  left_join(b_g, by = "genres") %>%
  left_join(b_t, by="timestamp") %>%
  mutate(pred = mu + b_i + b_u + b_g + b_t) %>%
  pull(pred)

regularised_m_u_g_t_rmse<-RMSE(predicted_ratings, test_set$rating)

rmse_results<- bind_rows(rmse_results, data_frame(method = "Regularised movie + user + genre + timestamp effect model",
                                                  RMSE = regularised_m_u_g_t_rmse))
knitr::kable(rmse_results)

```

This is the model we choose to use to predict the ratings in the validation set.

## 6. Results

``` {r, echo = FALSE}
# changing the timestamp format first
class(validation$timestamp)<- c('POSIXt','POSIXct')
validation$timestamp<- format(as.Date(validation$timestamp), "%Y-%m")
class(edx$timestamp)<- c('POSIXt','POSIXct')
edx$timestamp<- format(as.Date(edx$timestamp), "%Y-%m")

```

Using the regularized model accounting for a combination of movie, user, genre and time of rating effect with a penalty term, user bias, movie bias, genre bias and time of rating bias, we achieve a predictive model that when trained on the edx set produces RMSE of 0.8643 wich brings us in the desired range (RMSE <= 0.86490).

``` {r, echo = TRUE}
mu <- mean(edx$rating)
lambda<- 5 #from the above fitting

# creating the reglurarised estimates
b_i <- edx %>% 
  group_by(movieId) %>%
  summarize(b_i = sum(rating - mu)/(n()+lambda))

b_u <- edx %>% 
  left_join(b_i, by="movieId") %>%
  group_by(userId) %>%
  summarize(b_u = sum(rating - b_i - mu)/(n()+lambda))

b_g <- edx %>% 
  left_join(b_i, by="movieId") %>%
  left_join(b_u, by = "userId") %>%
  group_by(genres) %>%
  summarize(b_g = sum(rating - b_i - b_u - mu)/(n()+lambda))

b_t <- edx %>% 
  left_join(b_i, by="movieId") %>%
  left_join(b_u, by = "userId") %>%
  left_join(b_g, by="genres") %>%
  group_by(timestamp) %>%
  summarize(b_t = sum(rating - b_i - b_u-b_g - mu)/(n()+lambda))

#predicting the ratings
predicted_ratings <- 
  validation %>% 
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = "userId") %>%
  left_join(b_g, by = "genres") %>%
  left_join(b_t, by="timestamp") %>%
  mutate(pred = mu + b_i + b_u + b_g + b_t) %>%
  pull(pred)

# RMSE result ----
RMSE(predicted_ratings, validation$rating)

```


## 7. Conclusion

This report took us through the MoveLens 10M data set provided by GroupLens and pre-processed by HarvardX to allow for smooth exploratory analysis and modelling.

The entire set was split 90/10 to achieve edx and validation sets, used for modelling the data and validating the final model respectively.

The set contained 10M observations of 6 variables wich were explored in detail in the Exploratory Analysis section of this report. It also gave interesting insight into most popular movies, genres and user bahaviour.

The predictive model that best fit the data and provided the lowest RMSE amongst the models explored was the last one, which accounted for regularised user, movie, genre and time of rating biases, thereby providing a close estimate of the actual ratings presented in the validation set. The results of each of the models explored are summarised in the table below:

```{r,echo= FALSE}
knitr::kable(rmse_results)

```


## 8. Limitations and further work

Only 6 models were explored in predicting the ratings in the validation set, and due to the data size and low processing computer power those were all "processing-light" methods which allow for the code to be run on any machine.

To create more precise predictions, other predictive methodologies can be explored, such as regression trees for example. 

